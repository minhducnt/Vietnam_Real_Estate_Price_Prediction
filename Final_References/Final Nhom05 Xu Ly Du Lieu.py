# -*- coding: utf-8 -*-
"""FINAL_Nhom05_XuLyDuLieu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1__kyZSnmsJ7Hhobnzyu6UKEHnw3Szbjm

# SETUP MÔI TRƯỜNG
"""

# LINK DRIVE: https://drive.google.com/file/d/1kjiTlHpFcJ3B8EgVaRJfIiHVRXDTjuWp/view?usp=sharing
!pip install -q gdown

import gdown

file_id = '1kjiTlHpFcJ3B8EgVaRJfIiHVRXDTjuWp'
gdown.download(f"https://drive.google.com/uc?id={file_id}", "raw_dataset.csv", quiet=False)

# Cài đặt Java và Spark
!apt-get install openjdk-11-jdk-headless -qq > /dev/null
!wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz
!tar xf spark-3.3.0-bin-hadoop3.tgz
!pip install -q pyspark

# Thiết lập môi trường
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.3.0-bin-hadoop3"

# Khởi tạo SparkSession
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").appName("GoogleDriveSpark").getOrCreate()

"""# DATA TRƯỚC KHI XỬ LÝ"""

df = spark.read.option("header", True).csv("raw_dataset.csv")
df.show()

# Đếm tổng số dòng trong DataFrame
total_rows = df.count()
print(f"Tổng số dòng trong DataFrame: {total_rows}")

# Hiển thị kiểu dữ liệu của từng cột
df.printSchema()

from pyspark.sql.functions import col, sum
# Đếm số lượng null của từng cột
df.select([sum(col(c).isNull().cast("int")).alias(c) for c in df.columns]).show()

"""# DATA TRONG XỬ LÝ"""

from pyspark.sql.functions import col, sum

# Xóa 2 cột 'link' và 'title'
df_cleaned = df.drop('link', 'title')

# Xóa các dòng có giá trị null trong các cột 'price','area'
df_cleaned = df_cleaned.dropna(subset=['price', 'area'])

# Hiển thị kết quả sau khi xóa
df_cleaned.show(truncate=False)

# Đếm số lượng null của từng cột trong DataFrame df_cleaned
df_cleaned.select([sum(col(c).isNull().cast("int")).alias(c) for c in df_cleaned.columns]).show()

# Đếm tổng số dòng trong DataFrame df_cleaned
total_rows_cleaned = df_cleaned.count()
print(f"Tổng số dòng trong df_cleaned: {total_rows_cleaned}")

"""# Xử lý null"""

from pyspark.sql.functions import when

# Danh sách các cột số cần xử lý
numeric_columns_to_fill = [
    'floor_num', 'toilet_num', 'livingroom_num', 'bedroom_num'
]

# Với mỗi cột số, thay thế giá trị null bằng -1
for column_name in numeric_columns_to_fill:
    df_cleaned = df_cleaned.withColumn(
        column_name,
        when(col(column_name).isNull(), -1).otherwise(col(column_name))
    )

# Hiển thị kết quả sau khi xử lý
df_cleaned.select(numeric_columns_to_fill).show(truncate=False)

# Danh sách các cột chữ cần xử lý
columns_to_fill = [
    'category', 'direction', 'liability', 'location'
]

# Với mỗi cột, thay thế giá trị null bằng "Không xác định"
for column_name in columns_to_fill:
    df_cleaned = df_cleaned.withColumn(
        column_name,
        when(col(column_name).isNull(), 'Không xác định').otherwise(col(column_name))
    )

# Hiển thị kết quả sau khi xử lý
df_cleaned.select(columns_to_fill).show(truncate=False)

"""# XỬ LÝ CÁC CỘT DỮ LIỆU

# Xử lý cột Location thành cột district và city_province
"""

from pyspark.sql.functions import regexp_replace, split, trim, element_at, col
# regexp_replace(col('location'), r'\s*Lưu tin\s*$', ''): xóa 'Lưu tin' ở cuối location.
# split(..., ','): tách chuỗi thành mảng.
# element_at(..., -2) và element_at(..., -1): lấy phần tử áp chót và phần tử cuối cùng (quận/huyện, tỉnh/thành phố).
# trim(...): loại bỏ khoảng trắng thừa.

# 1. Xử lý trực tiếp trên location để tạo district và city_province
df_cleaned = df_cleaned.withColumn(
    'district',
    trim(element_at(split(regexp_replace(col('location'), r'\s*Lưu tin\s*$', ''), ','), -2))
).withColumn(
    'city_province',
    trim(element_at(split(regexp_replace(col('location'), r'\s*Lưu tin\s*$', ''), ','), -1))
)

# 2. Xóa cột location
df_cleaned = df_cleaned.drop('location')

# 3. Hiển thị kết quả
df_cleaned.select('district', 'city_province').show(truncate=False)

"""# Xử lý cột price"""

# Loại bỏ ký tự ~ và m2, sau đó thực hiện xử lý
df_cleaned = df_cleaned.withColumn('price',
    regexp_replace(col('price'), r'~', '')  # Loại bỏ ~ ở đầu
)

# Loại bỏ 'm2' ở cuối
df_cleaned = df_cleaned.withColumn('price',
    regexp_replace(col('price').cast('string'), r'\s*/m2$', '')  # Loại bỏ m2
)

# Hiển thị kết quả cuối cùng
df_cleaned.select('price').show(truncate=False)

from pyspark.sql import functions as F

# Thay triệu và nghìn thành số
df_cleaned = df_cleaned.withColumn(
    "price",
    F.when(
        F.col("price").contains("triệu"),
        (F.regexp_replace(
            F.regexp_replace(F.col("price"), "[^0-9,]", ""),  # Giữ lại số và dấu phẩy
            ",", "."
        ).cast("double") * 1_000_000)  # Nhân với 1 triệu
    ).when(
        F.col("price").contains("nghìn"),
        (F.regexp_replace(
            F.regexp_replace(F.col("price"), "[^0-9,]", ""),  # Giữ lại số và dấu phẩy
            ",", "."
        ).cast("double") * 1_000)  # Nhân với 1 nghìn
    ).otherwise(
        F.regexp_replace(F.col("price"), ",", "").cast("double")  # Bỏ dấu phẩy
    ).cast("float")  # Chuyển thành float
)

# Lọc bỏ các dòng có giá trị 'Thương lượng'
df_cleaned = df_cleaned.filter(~F.col("price").like("%Thương lượng%"))

# Hiển thị kết quả cuối cùng
df_cleaned.show(truncate=False)

"""# Xử lý cột area"""

# Loại bỏ 'm2' ở cuối chuỗi trong cột 'area'
df_cleaned = df_cleaned.withColumn('area',
    regexp_replace(col('area').cast('string'), r'\s*m2$', '')  # Loại bỏ 'm2' ở cuối và khoảng trắng trước nó
)

# Hiển thị 10 dòng đầu tiên sau khi làm sạch dữ liệu
df_cleaned.show(10, truncate=False)

"""# Xử lý cột floor_num"""

# Loại bỏ 'tầng' ở cuối chuỗi trong cột 'floor_num'
df_cleaned = df_cleaned.withColumn('floor_num',
    regexp_replace(col('floor_num').cast('string'), r'\s*tầng$', '')  # Loại bỏ 'm2' ở cuối và khoảng trắng trước nó
)

# Hiển thị 10 dòng đầu tiên sau khi làm sạch dữ liệu
df_cleaned.show(10, truncate=False)

"""# Xử lý cột bedroom_num"""

# Loại bỏ 'phòng' ở cuối chuỗi trong cột 'bedroom_num'
df_cleaned = df_cleaned.withColumn('bedroom_num',
    regexp_replace(col('bedroom_num').cast('string'), r'\s*phòng$', '')  # Loại bỏ 'phòng' ở cuối và khoảng trắng trước nó
)

# Hiển thị 10 dòng đầu tiên sau khi làm sạch dữ liệu
df_cleaned.show(10, truncate=False)

"""# Xử lý cột street"""

from pyspark.sql.functions import col, when, regexp_replace, split, lit

# 1. Bỏ chữ "m"
df_cleaned = df_cleaned.withColumn("street_clean", regexp_replace(col("street"), "m", ""))

# 2. Xử lý khoảng cách "a - b"
df_cleaned = df_cleaned.withColumn("split", split(col("street_clean"), "-"))

# 3. Tính giá trị trung bình và thay thế giá trị null bằng -1
df_cleaned = df_cleaned.withColumn(
    "street_float",
    when(
        col("street_clean").isNull(), lit(-1)  # Nếu cột street_clean là null, gán -1
    ).when(
        (col("split").getItem(1).isNotNull()),  # Nếu có dấu "-"
        (col("split").getItem(0).cast("float") + col("split").getItem(1).cast("float")) / 2
    ).otherwise(
        col("split").getItem(0).cast("float")  # Chỉ có 1 số
    )
)

# 4. Thay thế giá trị null trong cột street_float bằng -1
df_cleaned = df_cleaned.withColumn(
    "street_float",
    when(col("street_float").isNull(), lit(-1)).otherwise(col("street_float"))
)

# 5. Xóa các cột không cần thiết
df_cleaned = df_cleaned.drop("street", "street_clean", "split")

# Hiển thị kết quả cuối cùng
df_cleaned.select('street_float').show(truncate=False)

"""# Đổi kiểu dữ liệu"""

from pyspark.sql.functions import col

# Thay đổi kiểu dữ liệu của các cột
df_cleaned = df_cleaned.withColumn("area", col("area").cast("float")) \
                       .withColumn("floor_num", col("floor_num").cast("int")) \
                       .withColumn("toilet_num", col("toilet_num").cast("int")) \
                       .withColumn("livingroom_num", col("livingroom_num").cast("int")) \
                       .withColumn("bedroom_num", col("bedroom_num").cast("int")) \
                       .withColumn("street_float", col("street_float").cast("float"))

# Đổi tên các cột
df_cleaned = df_cleaned.withColumnRenamed("area", "area (m2)") \
                       .withColumnRenamed("street_float", "street (m)") \
                       .withColumnRenamed("price", "price_per_m2")

# Kiểm tra kiểu dữ liệu sau khi thay đổi
df_cleaned.printSchema()

"""# DATA SAU XỬ LÝ"""

# Đếm số lượng null của từng cột trong DataFrame df_cleaned
df_cleaned.select([sum(col(c).isNull().cast("int")).alias(c) for c in df_cleaned.columns]).show()

# Đếm tổng số dòng trong DataFrame df_cleaned
total_rows_cleaned = df_cleaned.count()
print(f"Tổng số dòng trong df_cleaned: {total_rows_cleaned}")

# Kiểm tra kiểu dữ liệu của các cột trong DataFrame df_cleaned
df_cleaned.printSchema()

df_cleaned.show()

"""# XUẤT FILE"""

# 1. Xuất file đã clean
df_cleaned.coalesce(1).write.csv('/content/cleaned_output', header=True, mode='overwrite')

# 2. Xác định đúng tên file
import os
output_files = os.listdir('/content/cleaned_output')
csv_file = [file for file in output_files if file.endswith('.csv')][0]
csv_file_path = '/content/cleaned_output/' + csv_file

# 3. Download
from google.colab import files
files.download(csv_file_path)